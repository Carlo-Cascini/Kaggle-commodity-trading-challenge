{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad80b812",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-02T09:34:26.238663Z",
     "iopub.status.busy": "2025-10-02T09:34:26.238292Z",
     "iopub.status.idle": "2025-10-02T09:39:22.630759Z",
     "shell.execute_reply": "2025-10-02T09:39:22.629928Z"
    },
    "papermill": {
     "duration": 296.401325,
     "end_time": "2025-10-02T09:39:22.634571",
     "exception": false,
     "start_time": "2025-10-02T09:34:26.233246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MITSUI COMMODITY PREDICTION - MODEL TRAINING & VALIDATION\n",
      "======================================================================\n",
      "Training: Rows 0-1826 (1827 rows)\n",
      "Testing:  Rows 1827-1956 (130 rows)\n",
      "======================================================================\n",
      "\n",
      "📂 Loading training data...\n",
      "Memory: 8.35 MB → 2.46 MB (70.6% reduction)\n",
      "Memory: 6.36 MB → 1.59 MB (75.0% reduction)\n",
      "Train shape: (1961, 558), Train labels shape: (1961, 425)\n",
      "\n",
      "🔧 Creating enhanced features...\n",
      "Memory: 2.67 MB → 2.60 MB (2.9% reduction)\n",
      "Total features: 597 (original + engineered)\n",
      "\n",
      "==================================================\n",
      "TRAINING MODEL\n",
      "==================================================\n",
      "X_train shape: (1827, 597)\n",
      "y_train shape: (1827, 424)\n",
      "\n",
      "🔄 Scaling features...\n",
      "\n",
      "🌳 Training Random Forest model...\n",
      "✅ Model training complete!\n",
      "\n",
      "============================================================\n",
      "VALIDATION ON KAGGLE PUBLIC LEADERBOARD DATA\n",
      "Testing on rows 1827-1956 (130 days)\n",
      "This will predict your expected leaderboard score!\n",
      "============================================================\n",
      "\n",
      "X_test shape: (130, 597)\n",
      "y_test shape: (130, 424)\n",
      "\n",
      "🔮 Making predictions...\n",
      "\n",
      "📊 Calculating rank-based Sharpe ratio...\n",
      "\n",
      "======================================================================\n",
      "RESULTS - EXPECTED KAGGLE PUBLIC LEADERBOARD SCORE\n",
      "======================================================================\n",
      "\n",
      "📈 Performance Metrics:\n",
      "   Rank-Based Sharpe Ratio:       0.180266\n",
      "   Expected Kaggle Score:         ~0.180\n",
      "\n",
      "💡 Interpretation:\n",
      "   Good score! Room for improvement but competitive.\n",
      "\n",
      "🏆 Top 10 Most Important Features:\n",
      "   US_Stock_EWY_adj_volume                  0.007552\n",
      "   US_Stock_EWT_adj_volume                  0.005698\n",
      "   JPX_Gold_Standard_Futures_Volume         0.004817\n",
      "   US_Stock_OXY_adj_volume                  0.004662\n",
      "   LME_AH_Close                             0.004619\n",
      "   FX_AUDJPY                                0.004608\n",
      "   US_Stock_MS_adj_volume                   0.004295\n",
      "   FX_EURAUD                                0.004157\n",
      "   FX_AUDNZD                                0.004154\n",
      "   US_Stock_VEA_adj_volume                  0.004134\n",
      "\n",
      "======================================================================\n",
      "NEXT STEPS:\n",
      "- This score should closely match Kaggle's public leaderboard\n",
      "- If it doesn't match, check data preprocessing or split\n",
      "- To improve: try ensemble models, more features, or hyperparameter tuning\n",
      "======================================================================\n",
      "\n",
      "🧪 Running local gateway test...\n",
      "✅ Local test complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MITSUI COMMODITY PREDICTION - KAGGLE SUBMISSION WITH VALIDATION\n",
    "================================================================\n",
    "HIGH-LEVEL PURPOSE:\n",
    "This code predicts future commodity price movements (spreads between pairs of commodities).\n",
    "Think of it like predicting if gold will rise more than silver tomorrow, or if copper \n",
    "will outperform aluminum. We look at 424 different pairs and predict their movements.\n",
    "\n",
    "The challenge: We only get ONE row of current prices to make predictions, like trying\n",
    "to predict tomorrow's weather with only today's temperature (no history!).\n",
    "\n",
    "IMPORTANT: Uses rank-based Sharpe ratio - we don't need exact returns, just correct rankings!\n",
    "\n",
    "Enhanced model with:\n",
    "- Memory optimization (70% reduction) - Makes the computer use less memory\n",
    "- Feature engineering (+75 production-safe features) - Creates smart measurements\n",
    "- Random Forest with optimized parameters - Our prediction machine\n",
    "- PROPER TRAIN/TEST SPLIT (0-1826 for training) - Avoids cheating by peeking at test data\n",
    "- RANK-BASED SHARPE VALIDATION - Matches Kaggle's exact scoring method\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries - These are like tools in a toolbox\n",
    "import pandas as pd  # Tool for working with tables of data\n",
    "import polars as pl  # Another faster tool for tables (Kaggle uses this)\n",
    "import numpy as np  # Tool for doing math with lots of numbers\n",
    "import random  # Tool for picking random numbers\n",
    "import time  # Tool for measuring how long things take\n",
    "import os, gc  # Tools for computer memory management\n",
    "import warnings  # Tool to hide annoying warning messages\n",
    "warnings.simplefilter('ignore')  # Tell Python to be quiet about warnings\n",
    "\n",
    "# Import machine learning tools\n",
    "from sklearn.preprocessing import StandardScaler  # Makes all numbers similar size\n",
    "from sklearn.ensemble import RandomForestRegressor  # Our prediction machine (like 100 decision trees voting)\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "class CFG:\n",
    "    \"\"\"Configuration settings - Like the rules of the game\"\"\"\n",
    "    path = \"/kaggle/input/mitsui-commodity-prediction-challenge/\"  # Where to find the data files\n",
    "    seed = 42  # Magic number that makes random things happen the same way each time\n",
    "    targets = [f\"target_{i}\" for i in range(424)]  # Names of 424 things we need to predict\n",
    "    solution_null_filler = 0.0  # What number to use when we don't know the answer\n",
    "    \n",
    "    # PROPER TRAIN/TEST SPLIT MATCHING KAGGLE\n",
    "    train_end = 1826      # Training: rows 0-1826 (1827 rows)\n",
    "    test_start = 1827     # Test start: row 1827\n",
    "    test_end = 1956       # Test end: row 1956 (130 test rows total)\n",
    "\n",
    "# ==============================================================================\n",
    "# MEMORY OPTIMIZATION FUNCTION -\n",
    "# ==============================================================================\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"\n",
    "    This function makes numbers smaller to save computer memory.\n",
    "    Like writing \"1M\" instead of \"1,000,000\" - same meaning, less space!\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2  # How much memory we're using now (in MB)\n",
    "    \n",
    "    # Look at each column (like each column in a spreadsheet)\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype  # What type of number is in this column?\n",
    "        \n",
    "        # If it's a number (not text)\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()  # Find the smallest number in this column\n",
    "            c_max = df[col].max()  # Find the biggest number in this column\n",
    "            \n",
    "            # If it's a whole number (like 1, 2, 3, not 1.5)\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Use the smallest box that fits the number\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)  # Tiny box (holds -128 to 127)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)  # Small box (holds -32,768 to 32,767)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)  # Medium box\n",
    "            else:  # If it's a decimal number (like 1.5, 2.7)\n",
    "                # Use the smallest decimal box that fits\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)  # Tiny decimal box\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)  # Small decimal box\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2  # How much memory after shrinking\n",
    "    print(f'Memory: {start_mem:.2f} MB → {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
    "    return df  # Give back the smaller data\n",
    "\n",
    "# KAGGLE'S RANK-BASED SHARPE RATIO METRIC \n",
    "# ==============================================================================\n",
    "\n",
    "def rank_correlation_sharpe_ratio(merged_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Sharpe ratio of rank correlations - the actual competition metric!\n",
    "    \n",
    "    This is special because it:\n",
    "    1. Ranks predictions from 1 to 424 (best to worst)\n",
    "    2. Ranks actual values from 1 to 424\n",
    "    3. Correlates these ranks (not the actual values!)\n",
    "    4. Calculates Sharpe ratio of daily correlations\n",
    "    \n",
    "    This means we only need to get the ORDER right, not exact values!\n",
    "    \"\"\"\n",
    "    # Find prediction and target columns\n",
    "    prediction_cols = [col for col in merged_df.columns if col.startswith('prediction_')]\n",
    "    target_cols = [col for col in merged_df.columns if col.startswith('target_')]\n",
    "\n",
    "    def _compute_rank_correlation(row):\n",
    "        \"\"\"Calculate rank correlation for one day\"\"\"\n",
    "        # Find targets that aren't missing (NaN)\n",
    "        non_null_targets = [col for col in target_cols if not pd.isnull(row[col])]\n",
    "        # Find matching predictions for those targets\n",
    "        matching_predictions = [col for col in prediction_cols if col.replace('prediction', 'target') in non_null_targets]\n",
    "        \n",
    "        # If no valid targets, return 0\n",
    "        if not non_null_targets:\n",
    "            return 0\n",
    "        \n",
    "        # If all values are the same (no variance), return 0\n",
    "        if row[non_null_targets].std(ddof=0) == 0 or row[matching_predictions].std(ddof=0) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate correlation between RANKS (not values!)\n",
    "        return np.corrcoef(\n",
    "            row[matching_predictions].rank(method='average'),  # Rank predictions 1-424\n",
    "            row[non_null_targets].rank(method='average')       # Rank actuals 1-424\n",
    "        )[0, 1]  # Get correlation coefficient\n",
    "\n",
    "    # Calculate rank correlation for each day\n",
    "    daily_rank_corrs = merged_df.apply(_compute_rank_correlation, axis=1)\n",
    "    \n",
    "    # Calculate Sharpe ratio (average correlation / standard deviation)\n",
    "    std_dev = daily_rank_corrs.std(ddof=0)\n",
    "    if std_dev == 0:\n",
    "        return 0\n",
    "    \n",
    "    sharpe_ratio = daily_rank_corrs.mean() / std_dev\n",
    "    return float(sharpe_ratio)\n",
    "\n",
    "# PREPROCESSING FUNCTION \n",
    "\n",
    "def preprocess_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fixes GOLD price columns that sometimes have text instead of numbers.\n",
    "    Like fixing \"1,000\" to be 1000.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Make a copy so we don't mess up the original\n",
    "    # List of GOLD columns that might be broken\n",
    "    columns = [\n",
    "        \"US_Stock_GOLD_adj_open\",  # Gold's opening price\n",
    "        \"US_Stock_GOLD_adj_high\",  # Gold's highest price of the day\n",
    "        \"US_Stock_GOLD_adj_low\",   # Gold's lowest price of the day\n",
    "        \"US_Stock_GOLD_adj_close\", # Gold's closing price\n",
    "        \"US_Stock_GOLD_adj_volume\" # How much gold was traded\n",
    "    ]\n",
    "    \n",
    "    # Fix each column if it exists and has text instead of numbers\n",
    "    for col in columns:\n",
    "        if col in df.columns and df[col].dtype == \"object\":  # If it's text, not a number\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to number\n",
    "    \n",
    "    return df\n",
    "\n",
    "# FEATURE ENGINEERING FUNCTIONS \n",
    "\n",
    "def create_commodity_ratios(df):\n",
    "    \"\"\"\n",
    "    Creates ratios between related commodities.\n",
    "    Like measuring how many silver coins equal one gold coin.\n",
    "    \"\"\"\n",
    "    # Gold/Silver ratio - How much more valuable is gold than silver?\n",
    "    if 'US_Stock_GOLD_adj_close' in df.columns and 'US_Stock_SLV_adj_close' in df.columns:\n",
    "        df['gold_silver_ratio'] = df['US_Stock_GOLD_adj_close'] / (df['US_Stock_SLV_adj_close'] + 1e-10)\n",
    "    \n",
    "    # Copper/Aluminum ratio - Industrial metals comparison\n",
    "    if 'LME_CU_Close' in df.columns and 'LME_AL_Close' in df.columns:\n",
    "        df['copper_aluminum_ratio'] = df['LME_CU_Close'] / (df['LME_AL_Close'] + 1e-10)\n",
    "    \n",
    "    # Zinc/Lead ratio - Battery metals comparison\n",
    "    if 'LME_ZS_Close' in df.columns and 'LME_PB_Close' in df.columns:\n",
    "        df['zinc_lead_ratio'] = df['LME_ZS_Close'] / (df['LME_PB_Close'] + 1e-10)\n",
    "    \n",
    "    # Nickel/Copper ratio - Electronics metals comparison\n",
    "    if 'LME_NI_Close' in df.columns and 'LME_CU_Close' in df.columns:\n",
    "        df['nickel_copper_ratio'] = df['LME_NI_Close'] / (df['LME_CU_Close'] + 1e-10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_currency_adjusted_prices(df):\n",
    "    \"\"\"\n",
    "    Adjusts commodity prices for different currencies.\n",
    "    Like converting the price of a toy from dollars to euros or yen.\n",
    "    \"\"\"\n",
    "    # If we have gold prices in dollars\n",
    "    if 'US_Stock_GOLD_adj_close' in df.columns:\n",
    "        # Convert gold price to euros (European money)\n",
    "        if 'FX_EURUSD' in df.columns:\n",
    "            df['gold_in_eur'] = df['US_Stock_GOLD_adj_close'] / (df['FX_EURUSD'] + 1e-10)\n",
    "        # Convert gold price to British pounds\n",
    "        if 'FX_GBPUSD' in df.columns:\n",
    "            df['gold_in_gbp'] = df['US_Stock_GOLD_adj_close'] / (df['FX_GBPUSD'] + 1e-10)\n",
    "        # Convert gold price to Japanese yen\n",
    "        if 'FX_USDJPY' in df.columns:\n",
    "            df['gold_in_jpy'] = df['US_Stock_GOLD_adj_close'] * df['FX_USDJPY']\n",
    "    \n",
    "    # If we have copper prices\n",
    "    if 'LME_CU_Close' in df.columns:\n",
    "        # Convert copper to British pounds\n",
    "        if 'FX_GBPUSD' in df.columns:\n",
    "            df['copper_in_gbp'] = df['LME_CU_Close'] / (df['FX_GBPUSD'] + 1e-10)\n",
    "        # Convert copper to euros\n",
    "        if 'FX_EURUSD' in df.columns:\n",
    "            df['copper_in_eur'] = df['LME_CU_Close'] / (df['FX_EURUSD'] + 1e-10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_intraday_features(df):\n",
    "    \"\"\"\n",
    "    Creates features from daily high/low/open/close prices.\n",
    "    Like measuring how wild the price moved during the day.\n",
    "    \"\"\"\n",
    "    assets = set()  # Empty list to collect asset names\n",
    "    # Find all assets that have closing prices\n",
    "    for col in df.columns:\n",
    "        if '_Close' in col:\n",
    "            asset = col.replace('_Close', '')  # Get the asset name\n",
    "            # Check if we also have High and Low prices\n",
    "            if f'{asset}_High' in df.columns and f'{asset}_Low' in df.columns:\n",
    "                assets.add(asset)\n",
    "    \n",
    "    # For the first 15 assets (to save time)\n",
    "    for asset in list(assets)[:15]:\n",
    "        if f'{asset}_High' in df.columns and f'{asset}_Low' in df.columns:\n",
    "            # How much did price move today? (as percentage)\n",
    "            df[f'{asset}_intraday_range'] = (\n",
    "                (df[f'{asset}_High'] - df[f'{asset}_Low']) / (df[f'{asset}_Close'] + 1e-10)\n",
    "            )\n",
    "            # Where did we close? (0 = at lowest, 1 = at highest)\n",
    "            df[f'{asset}_close_position'] = (\n",
    "                (df[f'{asset}_Close'] - df[f'{asset}_Low']) / \n",
    "                (df[f'{asset}_High'] - df[f'{asset}_Low'] + 1e-10)\n",
    "            )\n",
    "            # High/Low spread\n",
    "            df[f'{asset}_hl_spread'] = df[f'{asset}_High'] / (df[f'{asset}_Low'] + 1e-10) - 1\n",
    "            \n",
    "            # If we also have opening price\n",
    "            if f'{asset}_Open' in df.columns:\n",
    "                # Did price go up or down today?\n",
    "                df[f'{asset}_intraday_return'] = (\n",
    "                    (df[f'{asset}_Close'] - df[f'{asset}_Open']) / (df[f'{asset}_Open'] + 1e-10)\n",
    "                )\n",
    "                # Was it a green day (1) or red day (0)?\n",
    "                df[f'{asset}_bullish_day'] = (df[f'{asset}_Close'] > df[f'{asset}_Open']).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_market_indices(df):\n",
    "    \"\"\"\n",
    "    Creates average prices for groups of similar assets.\n",
    "    Like calculating the average score of all students in a class.\n",
    "    \"\"\"\n",
    "    # Find all London Metal Exchange metals\n",
    "    lme_cols = [col for col in df.columns if 'LME_' in col and '_Close' in col]\n",
    "    if len(lme_cols) > 0:\n",
    "        df['lme_metals_mean'] = df[lme_cols].mean(axis=1)  # Average price\n",
    "        df['lme_metals_std'] = df[lme_cols].std(axis=1)   # How different are prices?\n",
    "    \n",
    "    # Find all US stocks\n",
    "    us_cols = [col for col in df.columns if 'US_Stock_' in col and 'adj_close' in col]\n",
    "    if len(us_cols) > 0:\n",
    "        df['us_stocks_mean'] = df[us_cols].mean(axis=1)  # Average stock price\n",
    "    \n",
    "    # Find all USD currency pairs\n",
    "    usd_pairs = [col for col in df.columns if 'FX_' in col and 'USD' in col]\n",
    "    if len(usd_pairs) > 0:\n",
    "        df['usd_strength_index'] = df[usd_pairs].mean(axis=1)  # Dollar strength\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_spread_features(df):\n",
    "    \"\"\"\n",
    "    Creates price differences between related assets.\n",
    "    Like measuring the gap between first and second place in a race.\n",
    "    \"\"\"\n",
    "    # Gold minus Silver price\n",
    "    if 'US_Stock_GOLD_adj_close' in df.columns and 'US_Stock_SLV_adj_close' in df.columns:\n",
    "        df['gold_silver_spread'] = df['US_Stock_GOLD_adj_close'] - df['US_Stock_SLV_adj_close']\n",
    "    \n",
    "    # Copper minus Aluminum\n",
    "    if 'LME_CU_Close' in df.columns and 'LME_AL_Close' in df.columns:\n",
    "        df['copper_aluminum_spread'] = df['LME_CU_Close'] - df['LME_AL_Close']\n",
    "    \n",
    "    # Gold minus Copper (precious vs industrial)\n",
    "    if 'US_Stock_GOLD_adj_close' in df.columns and 'LME_CU_Close' in df.columns:\n",
    "        df['gold_copper_spread'] = df['US_Stock_GOLD_adj_close'] - df['LME_CU_Close']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_all_features(df):\n",
    "    \"\"\"\n",
    "    Master function that creates ALL the smart measurements.\n",
    "    Like a chef combining all ingredients to make a meal.\n",
    "    \"\"\"\n",
    "    # Create all different types of features\n",
    "    df = create_commodity_ratios(df)        # Add ratios\n",
    "    df = create_currency_adjusted_prices(df) # Add currency-adjusted prices\n",
    "    df = create_intraday_features(df)       # Add daily movement features\n",
    "    df = create_market_indices(df)          # Add market averages\n",
    "    df = create_spread_features(df)         # Add price differences\n",
    "    \n",
    "    # Handle broken values\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)  # Replace infinity with missing\n",
    "    df = df.fillna(0)  # Replace missing with 0\n",
    "    \n",
    "    # Clip extreme values\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].clip(-1e10, 1e10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD AND PREPARE TRAINING DATA\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MITSUI COMMODITY PREDICTION - MODEL TRAINING & VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training: Rows 0-{CFG.train_end} ({CFG.train_end + 1} rows)\")\n",
    "print(f\"Testing:  Rows {CFG.test_start}-{CFG.test_end} ({CFG.test_end - CFG.test_start + 1} rows)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n📂 Loading training data...\")\n",
    "# Read the training data file (like opening an Excel file)\n",
    "train = pd.read_csv(CFG.path + \"train.csv\").sort_values(\"date_id\")\n",
    "train = reduce_mem_usage(train)  # Make it smaller to save memory\n",
    "\n",
    "# Read the answers we're trying to predict\n",
    "train_labels = pd.read_csv(CFG.path + \"train_labels.csv\")\n",
    "train_labels = reduce_mem_usage(train_labels)\n",
    "\n",
    "print(f\"Train shape: {train.shape}, Train labels shape: {train_labels.shape}\")\n",
    "\n",
    "# Fix any broken GOLD columns\n",
    "train = preprocess_columns(train)\n",
    "\n",
    "# Create all our smart features\n",
    "print(\"\\n🔧 Creating enhanced features...\")\n",
    "train_enhanced = create_all_features(train.copy())\n",
    "train_enhanced = reduce_mem_usage(train_enhanced)\n",
    "\n",
    "# List all the features we'll use (everything except date_id)\n",
    "CFG.features = [c for c in train_enhanced.columns if c not in [\"date_id\"]]\n",
    "print(f\"Total features: {len(CFG.features)} (original + engineered)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PREPARE TRAINING DATA - PROPER SPLIT!\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"TRAINING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ONLY USE ROWS 0-1826 FOR TRAINING\n",
    "X_train = train_enhanced.iloc[:CFG.train_end+1][CFG.features].fillna(-1)\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Get the answers for training period only\n",
    "y_train = train_labels.iloc[:CFG.train_end+1][CFG.targets].fillna(CFG.solution_null_filler)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Scale features (make all numbers similar size)\n",
    "print(\"\\n🔄 Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "# ==============================================================================\n",
    "# TRAIN MODEL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n🌳 Training Random Forest model...\")\n",
    "# Create our prediction machine (Random Forest = many decision trees voting)\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=1000,        # Use 100 decision trees\n",
    "    max_depth=40,           # Each tree can ask up to 20 questions\n",
    "    min_samples_split=5,    # Need at least 5 examples to split\n",
    "    min_samples_leaf=2,     # Each final answer needs at least 2 examples\n",
    "    max_features='sqrt',    # Each tree looks at sqrt(features) randomly\n",
    "    random_state=CFG.seed,  # Makes it reproducible\n",
    "    n_jobs=-1,             # Use all computer cores\n",
    "    verbose=0              # Don't print progress\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"✅ Model training complete!\")\n",
    "\n",
    "# Clean up training data to save memory\n",
    "del X_train, X_train_scaled\n",
    "gc.collect()\n",
    "\n",
    "# ==============================================================================\n",
    "# VALIDATION - TEST ON LEADERBOARD ROWS TO PREDICT SCORE!\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION ON KAGGLE PUBLIC LEADERBOARD DATA\")\n",
    "print(\"Testing on rows 1827-1956 (130 days)\")\n",
    "print(\"This will predict your expected leaderboard score!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare test data (the rows Kaggle uses for scoring)\n",
    "X_test = train_enhanced.iloc[CFG.test_start:CFG.test_end+1][CFG.features].fillna(-1)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "y_test = train_labels.iloc[CFG.test_start:CFG.test_end+1][CFG.targets].fillna(CFG.solution_null_filler)\n",
    "\n",
    "print(f\"\\nX_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Scale and predict\n",
    "print(\"\\n🔮 Making predictions...\")\n",
    "X_test_scaled = scaler.transform(X_test).astype(np.float32)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RANK-BASED Sharpe ratio (Kaggle's metric)\n",
    "print(\"\\n📊 Calculating rank-based Sharpe ratio...\")\n",
    "\n",
    "# Prepare dataframes for metric calculation\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=CFG.targets)\n",
    "y_test_df = y_test.reset_index(drop=True)\n",
    "\n",
    "# Create solution and submission dataframes\n",
    "solution_df = y_test_df.copy()\n",
    "submission_df = y_pred_df.copy()\n",
    "\n",
    "# Rename prediction columns\n",
    "submission_df = submission_df.rename(columns={col: col.replace('target_', 'prediction_') \n",
    "                                             for col in submission_df.columns})\n",
    "\n",
    "# Merge for evaluation\n",
    "merged_df = pd.concat([solution_df, submission_df], axis=1)\n",
    "\n",
    "# Calculate the rank-based Sharpe ratio\n",
    "sharpe_ratio = rank_correlation_sharpe_ratio(merged_df)\n",
    "\n",
    "# ==============================================================================\n",
    "# DISPLAY RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS - EXPECTED KAGGLE PUBLIC LEADERBOARD SCORE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n📈 Performance Metrics:\")\n",
    "print(f\"   {'Rank-Based Sharpe Ratio:':<30} {sharpe_ratio:.6f}\")\n",
    "print(f\"   {'Expected Kaggle Score:':<30} ~{sharpe_ratio:.3f}\")\n",
    "print(f\"\\n💡 Interpretation:\")\n",
    "if sharpe_ratio > 0.2:\n",
    "    print(f\"   Excellent! This is a strong score for this competition.\")\n",
    "elif sharpe_ratio > 0.15:\n",
    "    print(f\"   Good score! Room for improvement but competitive.\")\n",
    "elif sharpe_ratio > 0.1:\n",
    "    print(f\"   Decent baseline. Consider more feature engineering.\")\n",
    "else:\n",
    "    print(f\"   Below average. Model may need significant improvements.\")\n",
    "\n",
    "# Show top features\n",
    "print(f\"\\n🏆 Top 10 Most Important Features:\")\n",
    "feature_importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': CFG.features,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for idx, row in importance_df.head(10).iterrows():\n",
    "    print(f\"   {row['feature'][:40]:<40} {row['importance']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"- This score should closely match Kaggle's public leaderboard\")\n",
    "print(\"- If it doesn't match, check data preprocessing or split\")\n",
    "print(\"- To improve: try ensemble models, more features, or hyperparameter tuning\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Clean up\n",
    "del X_test, X_test_scaled, y_test, y_pred\n",
    "gc.collect()\n",
    "\n",
    "# ==============================================================================\n",
    "# PREDICTION FUNCTION FOR KAGGLE SUBMISSION\n",
    "# ==============================================================================\n",
    "\n",
    "def predict(\n",
    "    test: pl.DataFrame,\n",
    "    label_lags_1_batch: pl.DataFrame,\n",
    "    label_lags_2_batch: pl.DataFrame,\n",
    "    label_lags_3_batch: pl.DataFrame,\n",
    "    label_lags_4_batch: pl.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prediction function that Kaggle calls with new data.\n",
    "    Gets one row of current prices and must predict 424 spread returns.\n",
    "    \n",
    "    Remember: We're scored on RANKING, not exact values!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert from Polars to Pandas format\n",
    "    test_pd = test.to_pandas()\n",
    "    \n",
    "    # Fix any broken GOLD columns\n",
    "    test_pd = preprocess_columns(test_pd)\n",
    "    \n",
    "    # Create all our smart features (works with single row!)\n",
    "    test_enhanced = create_all_features(test_pd.copy())\n",
    "    \n",
    "    # Select our features and handle missing values\n",
    "    X_test = test_enhanced[CFG.features].fillna(-1)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    # Scale the features (using same scaling from training)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Make predictions using our trained model\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Create predictions dataframe\n",
    "    predictions = pd.DataFrame(pred, columns=CFG.targets)\n",
    "    \n",
    "    # Ensure all 424 targets have a prediction\n",
    "    for target in CFG.targets:\n",
    "        if target not in predictions.columns:\n",
    "            predictions[target] = CFG.solution_null_filler\n",
    "    \n",
    "    return predictions[CFG.targets]  # Return in correct order\n",
    "\n",
    "# ==============================================================================\n",
    "# KAGGLE SUBMISSION SERVER - This runs on Kaggle's computers\n",
    "# ==============================================================================\n",
    "\n",
    "import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "# Create the server that will call our predict function\n",
    "inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "\n",
    "# Check if we're running on Kaggle or locally\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # We're on Kaggle - start the prediction server\n",
    "    print(\"🚀 Starting Kaggle inference server...\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # We're testing locally - run a test\n",
    "    print(\"🧪 Running local gateway test...\")\n",
    "    inference_server.run_local_gateway((CFG.path,))\n",
    "    print(\"✅ Local test complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13613251,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 302.822677,
   "end_time": "2025-10-02T09:39:23.759025",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-02T09:34:20.936348",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
